{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "from scipy.optimize import minimize\n",
    "import quadprog\n",
    "\n",
    "def linear_solver(n, M):\n",
    "\tM -= np.amin(M)\t# Let zero sum game at least with nonnegative payoff\n",
    "\tc = np.ones((n))\n",
    "\tb = np.ones((n))\n",
    "\tres = linprog(-c, A_ub = M.T, b_ub = b)\n",
    "\tw = res.x\n",
    "\treturn w/np.sum(w)\n",
    "\n",
    "def quadratic_solver(n, M, bbb , regularizer):\n",
    "    qp_G = np.matmul(M, M.T)\n",
    "    qp_G += regularizer * np.eye(n)\n",
    "\n",
    "    qp_a = np.matmul(M, bbb)###np.zeros(n, dtype = np.float64)\n",
    "\n",
    "    qp_C = np.zeros((n,n+1), dtype = np.float64)\n",
    "    for i in range(n):\n",
    "        qp_C[i,0] = 1.0\n",
    "        qp_C[i,i+1] = 1.0\n",
    "    qp_b = np.zeros(n+1, dtype = np.float64)\n",
    "    qp_b[0] = 1.0\n",
    "    meq =1\n",
    "    res = quadprog.solve_qp(qp_G, qp_a, qp_C, qp_b, meq)\n",
    "    w = res[0]\n",
    "    return w\n",
    "\n",
    "\"\"\"\n",
    "def quadratic_solver(n, M, bbb , regularizer):\n",
    "    qp_G = np.matmul(M, M.T)\n",
    "    qp_G += regularizer * np.eye(n)\n",
    "\n",
    "    qp_a = np.matmul(M, bbb)###np.zeros(n, dtype = np.float64)\n",
    "\n",
    "    qp_C = np.zeros((n,n), dtype = np.float64)\n",
    "    for i in range(n):\n",
    "        qp_C[i,0] = 0.0\n",
    "        qp_C[i,i] = 1.0\n",
    "    qp_b = np.zeros(n, dtype = np.float64)\n",
    "    qp_b[0] = 0.0\n",
    "    meq =0.0\n",
    "    res = quadprog.solve_qp(qp_G, qp_a, qp_C, qp_b, meq)\n",
    "    w = res[0]\n",
    "    return w\n",
    "\"\"\"\n",
    "'''\n",
    "def quadratic_solver_extend(n, M, b, regularizer):\n",
    "\tqp_G = np.matmul(M, M.T)\n",
    "\tqp_G += regularizer * np.eye(n)\n",
    "\t\n",
    "\tqp_a = np.matmul(b[None, :], M.T).reshape(-1)\n",
    "\n",
    "\tqp_C = np.zeros((n,n+1), dtype = np.float64)\n",
    "\tfor i in range(n):\n",
    "\t\tqp_C[i,0] = 1.0\n",
    "\t\tqp_C[i,i+1] = 1.0\n",
    "\tqp_b = np.zeros(n+1, dtype = np.float64)\n",
    "\tqp_b[0] = 1.0\n",
    "\tmeq = 1\n",
    "\tres = quadprog.solve_qp(qp_G, qp_a, qp_C, qp_b, meq)\n",
    "\tw = res[0]\n",
    "\treturn w\n",
    "'''\n",
    "\n",
    "class Density_Ratio_discrete(object):\n",
    "    def __init__(self, num_state):\n",
    "        self.num_state = num_state\n",
    "        self.Ghat = np.zeros([num_state, num_state], dtype = np.float64)\n",
    "        self.Nstate = np.zeros([num_state, 1], dtype = np.float64)\n",
    "\n",
    "    def reset(self):\n",
    "        num_state = self.num_state\n",
    "        self.Ghat = np.zeros([num_state, num_state], dtype = np.float64)\n",
    "        self.Nstate = np.zeros([num_state, 1], dtype = np.float64)\n",
    "\n",
    "    def feed_data(self, cur, next, policy_ratio):\n",
    "        self.Ghat[cur, next] += policy_ratio\n",
    "        self.Ghat[next, next] -= 1.0\n",
    "        self.Nstate[cur] += 0.5\n",
    "        self.Nstate[next] += 0.5\n",
    "\n",
    "    def density_ratio_estimate_old(self):\n",
    "        Frequency = (self.Nstate + 1e-5)\n",
    "        Frequency = Frequency / np.sum(Frequency)\n",
    "        G = self.Ghat / Frequency\n",
    "        n = self.num_state\n",
    "        x = quadratic_solver(n, G/100.0)\n",
    "        #x2 = linear_solver(n, G)\n",
    "        #print x\n",
    "        #print x2\n",
    "        #print np.sum((x-x2)*(x-x2))\n",
    "        w = x/Frequency.reshape(-1)\n",
    "        return x, w\n",
    "\n",
    "    def density_ratio_estimate(self, regularizer = 0.001):\n",
    "        Frequency = self.Nstate.flat\n",
    "        tvalid = np.where(Frequency >= 1e-9)\t\n",
    "        G = np.zeros_like(self.Ghat)\n",
    "        Frequency = Frequency/np.sum(Frequency)\n",
    "        G[tvalid] = self.Ghat[tvalid]/(Frequency[:,None])[tvalid]\t\t\n",
    "        n = self.num_state\n",
    "        x = quadratic_solver(n, G/50.0, regularizer)\n",
    "        w = np.zeros(self.num_state)\n",
    "        w[tvalid] = x[tvalid]/Frequency[tvalid]\n",
    "        return x, w\n",
    "\n",
    "    def density_ratio_estimate_exact(self):\n",
    "        Frequency = self.Nstate.flat\n",
    "        tvalid = np.where(Frequency >= 1e-9)\t\n",
    "        G = np.zeros_like(self.Ghat)\n",
    "        Frequency = Frequency/np.sum(Frequency)\n",
    "        G = self.Ghat[tvalid, tvalid]/(Frequency[:,None])[tvalid]\n",
    "        G = G/np.linalg.norm(G, 'fro')\n",
    "        n = Frequency[tvalid].shape[0]\n",
    "        x = np.zeros(self.num_state)\n",
    "        x[tvalid] = quadratic_solver(n, G)\n",
    "        w = np.zeros(self.num_state)\n",
    "        w[tvalid] = x[tvalid]/Frequency[tvalid]\n",
    "        return x, w\n",
    "\n",
    "class Density_Ratio_discounted(object):\n",
    "    def __init__(self, num_state, gamma):\n",
    "        self.num_state = num_state\n",
    "        self.Ghat = np.zeros([num_state, num_state], dtype = np.float64)\n",
    "        self.Nstate = np.zeros([num_state, 1], dtype = np.float64)\n",
    "        self.auxi = np.zeros([num_state, 1], dtype = np.float64)\n",
    "        self.gamma = gamma\n",
    "        #####self.initial_b = np.zeros([num_state], dtype = np.float64)self.gamma = gamma\n",
    "\n",
    "    def reset(self):\n",
    "        num_state = self.num_state\n",
    "        self.Ghat = np.zeros([num_state, num_state], dtype = np.float64)\n",
    "        self.Nstate = np.zeros([num_state, 1], dtype = np.float64)\n",
    "\n",
    "    def feed_data(self, cur, next, initial, policy_ratio, discounted_t):\n",
    "        if cur == -1:\n",
    "            self.Ghat[next, next] -= 1.0\n",
    "        else:\n",
    "            self.Ghat[cur, next] += self.gamma*policy_ratio \n",
    "            ###self.Ghat[cur, initial] += (1-self.gamma)/self.gamma * discounted_t\n",
    "            self.Ghat[next, next] -= 1.0 \n",
    "            self.auxi += (1.0-self.gamma)*1.0/self.num_state*np.ones([self.num_state, 1], dtype = np.float64)\n",
    "            ####self.Ghat[next, next] -= discounted_t\n",
    "            self.Nstate[cur] += 1.0 #####discounted_t\n",
    "\n",
    "    def density_ratio_estimate(self, regularizer = 0.001):\n",
    "        Frequency = self.Nstate.reshape(-1)\n",
    "        auxi = self.auxi.reshape(-1)\n",
    "        print self.auxi.shape\n",
    "        tvalid = np.where(Frequency >= 1e-3)\n",
    "        G = np.zeros_like(self.Ghat)\n",
    "        auxi = auxi*0.0\n",
    "        Frequency = Frequency/np.sum(Frequency)\n",
    "        auxi[tvalid] = self.auxi[tvalid].reshape(-1)####/Frequency[tvalid]\n",
    "        G[tvalid] = self.Ghat[tvalid]####/(Frequency[:,None])[tvalid]\t\t\n",
    "\n",
    "        n = self.num_state\n",
    "        np.save(\"GGG.npy\",G)\n",
    "        np.save(\"aixo.npy\",auxi)\n",
    "        np.save(\"frequency.npy\",Frequency)\n",
    "        x = quadratic_solver(n, G/10000.0,auxi/10000.0, 1.0*regularizer)\n",
    "        w = np.zeros(self.num_state)\n",
    "        w[tvalid] = x[tvalid]#####/Frequency[tvalid]        \n",
    "        ###w[w>3.0] = 0.0\n",
    "        return x, w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import optparse\n",
    "import subprocess\n",
    "import numpy as np\n",
    "#######from Density_Ratio_discrete import Density_Ratio_discrete, Density_Ratio_discounted\n",
    "from Q_learning import Q_learning\n",
    "from environment import random_walk_2d, taxi\n",
    "# import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.backends.backend_pdf import PdfPages\n",
    "# import seaborn as sns\n",
    "# sns.set(style=\"white\")\n",
    "\n",
    "\n",
    "def roll_out(state_num, env, policy, num_trajectory, truncate_size):\n",
    "    SASR = []\n",
    "    total_reward = 0.0\n",
    "    frequency = np.zeros(state_num)\n",
    "    for i_trajectory in range(num_trajectory):\n",
    "        state = env.reset()\n",
    "        sasr = []\n",
    "        for i_t in range(truncate_size):\n",
    "            #env.render()\n",
    "            p_action = policy[state, :]\n",
    "            action = np.random.choice(p_action.shape[0], 1, p = p_action)[0]\n",
    "            next_state, reward = env.step(action)\n",
    "\n",
    "            sasr.append((state, action, next_state, reward))\n",
    "            frequency[state] += 1\n",
    "            total_reward += reward\n",
    "            #print env.state_decoding(state)\n",
    "            #a = input()\n",
    "\n",
    "            state = next_state\n",
    "        SASR.append(sasr)\n",
    "    return SASR, frequency, total_reward/(num_trajectory * truncate_size)\n",
    "\n",
    "def train_density_ratio(SASR, policy0, policy1, den_discrete, gamma):\n",
    "    for sasr in SASR:\n",
    "        discounted_t = 1.0\n",
    "        initial_state = sasr[0,0]\n",
    "        for state, action, next_state, reward in sasr:\n",
    "            discounted_t = gamma\n",
    "            policy_ratio = policy1[state, action]/policy0[state, action]\n",
    "            den_discrete.feed_data(state, next_state, initial_state, policy_ratio, discounted_t)\n",
    "        ####den_discrete.feed_data(-1, initial_state, initial_state, 1, discounted_t)\n",
    "\n",
    "    x, w = den_discrete.density_ratio_estimate()\n",
    "    return x, w\n",
    "\n",
    "def off_policy_evaluation_density_ratio(SASR, policy0, policy1, density_ratio, gamma):\n",
    "    total_reward = 0.0\n",
    "    self_normalizer = 0.0\n",
    "    for sasr in SASR:\n",
    "        discounted_t = gamma\n",
    "        for state, action, next_state, reward in sasr:\n",
    "            policy_ratio = policy1[state, action]/policy0[state, action]\n",
    "            total_reward += density_ratio[state] * policy_ratio * reward #### * discounted_t\n",
    "            self_normalizer += density_ratio[state] * policy_ratio ######* discounted_t\n",
    "            #######discounted_t = gamma\n",
    "    return total_reward / self_normalizer\n",
    "\n",
    "def on_policy(SASR, gamma):\n",
    "    total_reward = 0.0\n",
    "    self_normalizer = 0.0\n",
    "    for sasr in SASR:\n",
    "        discounted_t = 1.0\n",
    "        for state, action, next_state, reward in sasr:\n",
    "            total_reward += reward * discounted_t\n",
    "            self_normalizer += discounted_t\n",
    "            discounted_t *= gamma\n",
    "    return total_reward / self_normalizer\n",
    "\n",
    "def importance_sampling_estimator(SASR, policy0, policy1, gamma):\n",
    "    mean_est_reward = 0.0\n",
    "    for sasr in SASR:\n",
    "        log_trajectory_ratio = 0.0\n",
    "        total_reward = 0.0\n",
    "        discounted_t = 1.0\n",
    "        self_normalizer = 0.0\n",
    "        for state, action, next_state, reward in sasr:\n",
    "            log_trajectory_ratio += np.log(policy1[state, action]) - np.log(policy0[state, action])\n",
    "            total_reward += reward * discounted_t\n",
    "            self_normalizer += discounted_t\n",
    "            discounted_t *= gamma\n",
    "        avr_reward = total_reward / self_normalizer\n",
    "        mean_est_reward += avr_reward * np.exp(log_trajectory_ratio)\n",
    "    mean_est_reward /= len(SASR)\n",
    "    return mean_est_reward\n",
    "\n",
    "def importance_sampling_estimator_stepwise(SASR, policy0, policy1, gamma):\n",
    "    mean_est_reward = 0.0\n",
    "    for sasr in SASR:\n",
    "        step_log_pr = 0.0\n",
    "        est_reward = 0.0\n",
    "        discounted_t = 1.0\n",
    "        self_normalizer = 0.0\n",
    "        for state, action, next_state, reward in sasr:\n",
    "            step_log_pr += np.log(policy1[state, action]) - np.log(policy0[state, action])\n",
    "            est_reward += np.exp(step_log_pr)*reward*discounted_t\n",
    "            self_normalizer += discounted_t\n",
    "            discounted_t *= gamma\n",
    "        est_reward /= self_normalizer\n",
    "        mean_est_reward += est_reward\n",
    "    mean_est_reward /= len(SASR)\n",
    "    return mean_est_reward\n",
    "\n",
    "def weighted_importance_sampling_estimator(SASR, policy0, policy1, gamma):\n",
    "    total_rho = 0.0\n",
    "    est_reward = 0.0\n",
    "    for sasr in SASR:\n",
    "        total_reward = 0.0\n",
    "        log_trajectory_ratio = 0.0\n",
    "        discounted_t = 1.0\n",
    "        self_normalizer = 0.0\n",
    "        for state, action, next_state, reward in sasr:\n",
    "            log_trajectory_ratio += np.log(policy1[state, action]) - np.log(policy0[state, action])\n",
    "            total_reward += reward * discounted_t\n",
    "            self_normalizer += discounted_t\n",
    "            discounted_t *= gamma\n",
    "        avr_reward = total_reward / self_normalizer\n",
    "        trajectory_ratio = np.exp(log_trajectory_ratio)\n",
    "        total_rho += trajectory_ratio\n",
    "        est_reward += trajectory_ratio * avr_reward\n",
    "\n",
    "    avr_rho = total_rho / len(SASR)\n",
    "    return est_reward / avr_rho/ len(SASR)\n",
    "\n",
    "def weighted_importance_sampling_estimator_stepwise(SASR, policy0, policy1, gamma):\n",
    "    Log_policy_ratio = []\n",
    "    REW = []\n",
    "    for sasr in SASR:\n",
    "        log_policy_ratio = []\n",
    "        rew = []\n",
    "        discounted_t = 1.0\n",
    "        self_normalizer = 0.0\n",
    "        for state, action, next_state, reward in sasr:\n",
    "            log_pr = np.log(policy1[state, action]) - np.log(policy0[state, action])\n",
    "            if log_policy_ratio:\n",
    "                log_policy_ratio.append(log_pr + log_policy_ratio[-1])\n",
    "            else:\n",
    "                log_policy_ratio.append(log_pr)\n",
    "            rew.append(reward * discounted_t)\n",
    "            self_normalizer += discounted_t\n",
    "            discounted_t *= gamma\n",
    "        Log_policy_ratio.append(log_policy_ratio)\n",
    "        REW.append(rew)\n",
    "    est_reward = 0.0\n",
    "    rho = np.exp(Log_policy_ratio)\n",
    "    #print 'rho shape = {}'.format(rho.shape)\n",
    "    REW = np.array(REW)\n",
    "    for i in range(REW.shape[0]):\n",
    "        est_reward += np.sum(rho[i]/np.mean(rho, axis = 0) * REW[i])/self_normalizer\n",
    "    return est_reward/REW.shape[0]\n",
    "\n",
    "\n",
    "def Q_learning(env, num_trajectory, truncate_size, temperature = 2.0):\n",
    "    agent = Q_learning(n_state, n_action, 0.01, 0.99)\n",
    "\n",
    "    state = env.reset()\n",
    "    for k in range(20):\n",
    "        print 'Training for episode {}'.format(k)\n",
    "        for i in range(50):\n",
    "            for j in range(5000):\n",
    "                action = agent.choose_action(state, temperature)\n",
    "                next_state, reward = env.step(action)\n",
    "                agent.update(state, action, next_state, reward)\n",
    "                state = next_state\n",
    "        pi = agent.get_pi(temperature)\n",
    "        np.save('taxi-policy/pi{}.npy'.format(k), pi)\n",
    "        SAS, f, avr_reward = roll_out(n_state, env, pi, num_trajectory, truncate_size)\n",
    "        print 'Episode {} reward = {}'.format(k, avr_reward)\n",
    "        heat_map(length, f, env, 'heatmap/pi{}.pdf'.format(k))\n",
    "\n",
    "def heat_map(length, f, env, filename):\n",
    "    p_matrix = np.zeros([length, length], dtype = np.float32)\n",
    "    for state in range(env.n_state):\n",
    "        x,y,_,_ = env.state_decoding(state)\n",
    "        #x,y = env.state_decoding(state)\n",
    "        p_matrix[x,y] = f[state]\n",
    "    p_matrix = p_matrix / np.sum(p_matrix)\n",
    "\n",
    "    sns.heatmap(p_matrix, cmap=\"YlGnBu\")#, vmin = 0.0, vmax = 0.07)\n",
    "    ppPDF = PdfPages(filename)\n",
    "    ppPDF.savefig()\n",
    "    ppPDF.close()\n",
    "    plt.clf()\n",
    "\n",
    "def model_based(n_state, n_action, SASR, pi, gamma):\n",
    "    T = np.zeros([n_state, n_action, n_state], dtype = np.float32)\n",
    "    R = np.zeros([n_state, n_action], dtype = np.float32)\n",
    "    R_count = np.zeros([n_state, n_action], dtype = np.int32)\n",
    "    for sasr in SASR:\n",
    "        for state, action, next_state, reward in sasr:\n",
    "            T[state, action, next_state] += 1\n",
    "            R[state, action] += reward\n",
    "            R_count[state, action] += 1\n",
    "    d0 = np.zeros([n_state, 1], dtype = np.float32)\n",
    "\n",
    "    for state in SASR[:,0,0].flat:\n",
    "        d0[state, 0] += 1.0\n",
    "    t = np.where(R_count > 0)\n",
    "    t0 = np.where(R_count == 0)\n",
    "    R[t] = R[t]/R_count[t]\n",
    "    R[t0] = np.mean(R[t])\n",
    "    T = T + 1e-9\t# smoothing\n",
    "    T = T/np.sum(T, axis = -1)[:,:,None]\n",
    "    Tpi = np.zeros([n_state, n_state])\n",
    "    for state in range(n_state):\n",
    "        for next_state in range(n_state):\n",
    "            for action in range(n_action):\n",
    "                Tpi[state, next_state] += T[state, action, next_state] * pi[state, action]\n",
    "    dt = d0/np.sum(d0)\n",
    "    dpi = np.zeros([n_state, 1], dtype = np.float32)\n",
    "    truncate_size = SASR.shape[1]\n",
    "    discounted_t = 1.0\n",
    "    self_normalizer = 0.0\n",
    "    for i in range(truncate_size):\n",
    "        dpi += dt * discounted_t\n",
    "        if i < 50:\n",
    "            dt = np.dot(Tpi.T,dt)\n",
    "        self_normalizer += discounted_t\n",
    "        discounted_t *= gamma\n",
    "    dpi /= self_normalizer\n",
    "    np.save(\"Tpi.npy\",Tpi)\n",
    "    np.save(\"R.npy\",R)\n",
    "    np.save(\"pi.npy\",pi)\n",
    "    Rpi = np.sum(R * pi, axis = -1)\n",
    "    np.save(\"Rpi.npy\",Rpi)\n",
    "    np.save(\"dpi.npy\",dpi)\n",
    "    return np.sum(dpi.reshape(-1) * Rpi)\n",
    "\n",
    "def run_experiment(n_state, n_action, SASR, pi0, pi1, gamma):\n",
    "\n",
    "    den_discrete = Density_Ratio_discounted(n_state, gamma)\n",
    "    x, w = train_density_ratio(SASR, pi0, pi1, den_discrete, gamma)\n",
    "    x = x.reshape(-1)\n",
    "    w = w.reshape(-1)\n",
    "    np.save(\"weight.npy\",w)\n",
    "    est_DENR = off_policy_evaluation_density_ratio(SASR, pi0, pi1, w, gamma)\n",
    "    est_naive_average = on_policy(SASR, gamma)\n",
    "    est_IST = importance_sampling_estimator(SASR, pi0, pi1, gamma)\n",
    "    est_ISS = importance_sampling_estimator_stepwise(SASR, pi0, pi1, gamma)\n",
    "    est_WIST = weighted_importance_sampling_estimator(SASR, pi0, pi1, gamma)\n",
    "    est_WISS = weighted_importance_sampling_estimator_stepwise(SASR, pi0, pi1, gamma)\n",
    "\n",
    "    est_model_based = model_based(n_state, n_action, SASR, pi1, gamma)\n",
    "    #return est_model_based\n",
    "    return est_DENR, est_naive_average, est_IST, est_ISS, est_WIST, est_WISS, est_model_based\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####if __name__ == '__main__':\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(2000, 1)\n",
      "------seed = 0------\n",
      "  ESTIMATOR: On Policy, rewards = -0.134589999914\n",
      "----------------------\n",
      "  ESTIMATOR: Density Ratio, rewards = -0.197024554014\n",
      "----------------------\n",
      "  ESTIMATOR: Naive Average, rewards = -0.192444995046\n",
      "----------------------\n",
      "  ESTIMATOR: IST, rewards = -0.204850807786\n",
      "----------------------\n",
      "  ESTIMATOR: ISS, rewards = -0.107262693346\n",
      "----------------------\n",
      "  ESTIMATOR: WIST, rewards = -0.207104235888\n",
      "----------------------\n",
      "  ESTIMATOR: WISS, rewards = -0.127428039908\n",
      "----------------------\n",
      "  ESTIMATOR: Model Based, rewards = -0.121982105076\n",
      "----------------------\n",
      "1\n",
      "(2000, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-202-fe392063aaf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mSASR0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroll_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_behavior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSASR0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_behavior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-201-5633d563b1f1>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(n_state, n_action, SASR, pi0, pi1, gamma)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0mest_WISS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_importance_sampling_estimator_stepwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSASR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0mest_model_based\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_based\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSASR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;31m#return est_model_based\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mest_DENR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest_naive_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest_IST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest_ISS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest_WIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest_WISS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest_model_based\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-201-5633d563b1f1>\u001b[0m in \u001b[0;36mmodel_based\u001b[0;34m(n_state, n_action, SASR, pi, gamma)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnext_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 \u001b[0mTpi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimator_name = ['On Policy', 'Density Ratio', 'Naive Average', 'IST', 'ISS', 'WIST', 'WISS', 'Model Based']\n",
    "length = 5\n",
    "env = taxi(length)\n",
    "n_state = env.n_state\n",
    "n_action = env.n_action\n",
    "\n",
    "num_trajectory = 200\n",
    "truncate_size = 400\n",
    "gamma = 1.0\n",
    "\n",
    "\"\"\"\n",
    "parser = argparse.ArgumentParser(description='taxi environment')\n",
    "parser.add_argument('--nt', type = int, required = False, default = num_trajectory)\n",
    "parser.add_argument('--ts', type = int, required = False, default = truncate_size)\n",
    "parser.add_argument('--gm', type = float, required = False, default = gamma)\n",
    "args = parser.parse_args()\n",
    "\"\"\"\n",
    "behavior_ID = 4\n",
    "target_ID = 5\n",
    "\n",
    "pi_target = np.load('taxi-policy/pi19.npy')\n",
    "alpha = 0.4  # mixture ratio\n",
    "nt = 200 # num_trajectory\n",
    "ts = 1000 # truncate_size\n",
    "gm = 1.0 # gamma\n",
    "pi_behavior = np.load('taxi-policy/pi18.npy')\n",
    "\n",
    "pi_behavior = alpha * pi_target + (1-alpha) * pi_behavior\n",
    "\n",
    "res = np.zeros((8, 20), dtype = np.float32)\n",
    "for k in range(20):\n",
    "    print k\n",
    "    np.random.seed(k)\n",
    "    SASR0, _, _ = roll_out(n_state, env, pi_behavior, nt, ts)\n",
    "    res[1:,k] = run_experiment(n_state, n_action, np.array(SASR0), pi_behavior, pi_target, gm)\n",
    "\n",
    "    np.random.seed(k)\n",
    "    SASR, _, _ = roll_out(n_state, env, pi_target, nt, ts)\n",
    "    res[0, k] = on_policy(np.array(SASR), gm)\n",
    "\n",
    "    print('------seed = {}------'.format(k))\n",
    "    for i in range(8):\n",
    "        print('  ESTIMATOR: '+estimator_name[i]+ ', rewards = {}'.format(res[i,k]))\n",
    "        print('----------------------')\n",
    "        sys.stdout.flush()\n",
    "        np.save('result/nt={}ts={}gm={}.npy'.format(nt,ts,gm), res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rpi = np.load(\"Rpi.npy\")\n",
    "dpi = np.load(\"dpi.npy\")\n",
    "dpi = np.load(\"R.npy\")\n",
    "Tpi = np.load(\"Tpi.npy\")\n",
    "R = np.load(\"R.npy\")\n",
    "pi = np.load(\"pi.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAEY5JREFUeJzt3X+s3Xddx/Hny9UNkEi39TpHW7xFGskgKst1zpAYw8zYBqFLBNxipOJMowx/zQQ6SVyCIRmROJ3RmcrKii774dSskSo2A4O/Nun4MTbG3HUU2rqxKxtTJILVt3+cT/Ws9Pa295x7Tnc/z0fyzf1+39/P9/v9fHZu7mvf7+ec01QVkqT+fMu0OyBJmg4DQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktSpNdPuwPGsW7euZmdnp90NSXpOuf/++/+1qmaWandKB8Ds7Cz79u2bdjck6TklyRdOpJ2PgCSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVOn9CeBJQlgdvuHpnbt/de/bmrXXmlL3gEk2ZnkySQPHmPfrySpJOvadpLcmGQ+yQNJzh9quzXJo23ZOt5hSJJO1ok8AroFuOToYpKNwMXAF4fKlwKb27INuKm1PQu4DvhB4ALguiRnjtJxSdJolgyAqvoY8NQxdt0AvAOoodoW4IM1cC+wNsm5wGuBvVX1VFU9DezlGKEiSZqcZU0CJ9kCHKqqTx+1az1wYGj7YKstVpckTclJTwIneQHwqwwe/4xdkm0MHh/xkpe8ZCUuIUlieXcA3w1sAj6dZD+wAfhEku8EDgEbh9puaLXF6t+kqnZU1VxVzc3MLPnvGUiSlumkA6CqPlNV31FVs1U1y+BxzvlV9QSwG3hLezfQhcAzVfU48GHg4iRntsnfi1tNkjQlJ/I20NuAfwC+J8nBJFcdp/ke4DFgHvgD4G0AVfUU8OvAx9vy7laTJE3JknMAVXXlEvtnh9YLuHqRdjuBnSfZP0nSCvGrICSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1KklAyDJziRPJnlwqPYbST6X5IEkf5Zk7dC+a5PMJ3kkyWuH6pe02nyS7eMfiiTpZJzIHcAtwCVH1fYCr6yq7wX+CbgWIMl5wBXAK9oxv5fktCSnAb8LXAqcB1zZ2kqSpmTJAKiqjwFPHVX7q6o63DbvBTa09S3A7VX19ar6PDAPXNCW+ap6rKq+Adze2kqSpmQccwA/DfxFW18PHBjad7DVFqtLkqZkpABI8i7gMHDreLoDSbYl2Zdk38LCwrhOK0k6yrIDIMlPAa8HfqKqqpUPARuHmm1otcXq36SqdlTVXFXNzczMLLd7kqQlLCsAklwCvAN4Q1V9bWjXbuCKJGck2QRsBv4R+DiwOcmmJKczmCjePVrXJUmjWLNUgyS3AT8CrEtyELiOwbt+zgD2JgG4t6p+tqoeSnIn8FkGj4aurqr/bud5O/Bh4DRgZ1U9tALjkSSdoCUDoKquPEb55uO0fw/wnmPU9wB7Tqp3kqQV4yeBJalTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUqSUDIMnOJE8meXCodlaSvUkebT/PbPUkuTHJfJIHkpw/dMzW1v7RJFtXZjiSpBN1IncAtwCXHFXbDtxTVZuBe9o2wKXA5rZsA26CQWAA1wE/CFwAXHckNCRJ07FkAFTVx4CnjipvAXa19V3A5UP1D9bAvcDaJOcCrwX2VtVTVfU0sJdvDhVJ0gQtdw7gnKp6vK0/AZzT1tcDB4baHWy1xerfJMm2JPuS7FtYWFhm9yRJSxl5EriqCqgx9OXI+XZU1VxVzc3MzIzrtJKkoyw3AL7UHu3Qfj7Z6oeAjUPtNrTaYnVJ0pQsNwB2A0feybMVuHuo/pb2bqALgWfao6IPAxcnObNN/l7capKkKVmzVIMktwE/AqxLcpDBu3muB+5MchXwBeDNrfke4DJgHvga8FaAqnoqya8DH2/t3l1VR08sS5ImaMkAqKorF9l10THaFnD1IufZCew8qd5JklaMnwSWpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnRgqAJL+c5KEkDya5LcnzkmxKcl+S+SR3JDm9tT2jbc+3/bPjGIAkaXmWHQBJ1gO/AMxV1SuB04ArgPcCN1TVy4CngavaIVcBT7f6Da2dJGlKRn0EtAZ4fpI1wAuAx4HXAHe1/buAy9v6lrZN239Rkox4fUnSMi07AKrqEPA+4IsM/vA/A9wPfKWqDrdmB4H1bX09cKAde7i1P/vo8ybZlmRfkn0LCwvL7Z4kaQmjPAI6k8H/1W8CXgx8G3DJqB2qqh1VNVdVczMzM6OeTpK0iFEeAf0o8PmqWqiq/wL+FHg1sLY9EgLYABxq64eAjQBt/4uAL49wfUnSCEYJgC8CFyZ5QXuWfxHwWeCjwBtbm63A3W19d9um7f9IVdUI15ckjWCUOYD7GEzmfgL4TDvXDuCdwDVJ5hk847+5HXIzcHarXwNsH6HfkqQRrVm6yeKq6jrguqPKjwEXHKPtfwJvGuV6kqTx8ZPAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnq1EgBkGRtkruSfC7Jw0l+KMlZSfYmebT9PLO1TZIbk8wneSDJ+eMZgiRpOUa9A/ht4C+r6uXA9wEPA9uBe6pqM3BP2wa4FNjclm3ATSNeW5I0gmUHQJIXAT8M3AxQVd+oqq8AW4Bdrdku4PK2vgX4YA3cC6xNcu6yey5JGskodwCbgAXgA0k+meT9Sb4NOKeqHm9tngDOaevrgQNDxx9stWdJsi3JviT7FhYWRuieJOl4RgmANcD5wE1V9SrgP/j/xz0AVFUBdTInraodVTVXVXMzMzMjdE+SdDyjBMBB4GBV3de272IQCF868min/Xyy7T8EbBw6fkOrSZKmYNkBUFVPAAeSfE8rXQR8FtgNbG21rcDdbX038Jb2bqALgWeGHhVJkiZszYjH/zxwa5LTgceAtzIIlTuTXAV8AXhza7sHuAyYB77W2kqSpmSkAKiqTwFzx9h10THaFnD1KNeTJI2PnwSWpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROjfpVEJK0qs1u/9BUrrv/+tet+DW8A5CkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE6NHABJTkvyySR/3rY3JbkvyXySO9o/GE+SM9r2fNs/O+q1JUnLN447gF8EHh7afi9wQ1W9DHgauKrVrwKebvUbWjtJ0pSMFABJNgCvA97ftgO8BrirNdkFXN7Wt7Rt2v6LWntJ0hSMegfwW8A7gP9p22cDX6mqw237ILC+ra8HDgC0/c+09pKkKVh2ACR5PfBkVd0/xv6QZFuSfUn2LSwsjPPUkqQho9wBvBp4Q5L9wO0MHv38NrA2yZGvmd4AHGrrh4CNAG3/i4AvH33SqtpRVXNVNTczMzNC9yRJx7PsAKiqa6tqQ1XNAlcAH6mqnwA+CryxNdsK3N3Wd7dt2v6PVFUt9/qSpNGsxOcA3glck2SewTP+m1v9ZuDsVr8G2L4C15YknaCx/ItgVfXXwF+39ceAC47R5j+BN43jepKk0flJYEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdWrZAZBkY5KPJvlskoeS/GKrn5Vkb5JH288zWz1Jbkwyn+SBJOePaxCSpJM3yh3AYeBXquo84ELg6iTnAduBe6pqM3BP2wa4FNjclm3ATSNcW5I0omUHQFU9XlWfaOv/DjwMrAe2ALtas13A5W19C/DBGrgXWJvk3GX3XJI0krHMASSZBV4F3AecU1WPt11PAOe09fXAgaHDDraaJGkKRg6AJC8E/gT4par6t+F9VVVAneT5tiXZl2TfwsLCqN2TJC1ipABI8q0M/vjfWlV/2spfOvJop/18stUPARuHDt/Qas9SVTuqaq6q5mZmZkbpniTpOEZ5F1CAm4GHq+o3h3btBra29a3A3UP1t7R3A10IPDP0qEiSNGFrRjj21cBPAp9J8qlW+1XgeuDOJFcBXwDe3PbtAS4D5oGvAW8d4dqSpBEtOwCq6m+BLLL7omO0L+Dq5V5PkjRefhJYkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHVqlH8P4JQ3u/1DU7nu/utfN5XrStLJ8A5AkjplAEhSpwwASeqUASBJnTIAJKlTEw+AJJckeSTJfJLtk76+JGlgogGQ5DTgd4FLgfOAK5OcN8k+SJIGJn0HcAEwX1WPVdU3gNuBLRPugySJyQfAeuDA0PbBVpMkTdgp90ngJNuAbW3zq0keGeF064B/Hb1XJyfvXfFLTGVcE+LYnptW69imNq4R/45814k0mnQAHAI2Dm1vaLX/U1U7gB3juFiSfVU1N45znUpW67jAsT1XrdaxrdZxHTHpR0AfBzYn2ZTkdOAKYPeE+yBJYsJ3AFV1OMnbgQ8DpwE7q+qhSfZBkjQw8TmAqtoD7JnQ5cbyKOkUtFrHBY7tuWq1jm21jguAVNW0+yBJmgK/CkKSOnVKB8BSXxuR5Iwkd7T99yWZHdp3bas/kuS1S52zTUzf1+p3tEnq1TK2t7daJVm3isZ1a6s/mGRnkm9dRWO7OcmnkzyQ5K4kL1wtYxvaf2OSr67UmE6iH+N83W5J8vkkn2rL96/0+EZSVafkwmCS+J+BlwKnA58GzjuqzduA32/rVwB3tPXzWvszgE3tPKcd75zAncAVbf33gZ9bRWN7FTAL7AfWraJxXQakLbetstfs24fO+5vA9tUytnbcHPCHwFdXalxTet1uAd64kmMa53Iq3wGcyNdGbAF2tfW7gIuSpNVvr6qvV9Xngfl2vmOesx3zmnYO2jkvXw1jA6iqT1bV/hUczxGTHteeaoB/ZPC5ktUytn8DaMc/H1jJybqJji2D7wT7DeAdKzimIyY6tueaUzkATuRrI/6vTVUdBp4Bzj7OsYvVzwa+0s6x2LXGaZJjm6SpjKs9+vlJ4C9HHsHiJj62JB8AngBeDvzOOAaxiEmP7e3A7qp6fEz9P55p/E6+pz26uyHJGeMYxEo5lQNAOlG/B3ysqv5m2h0Zp6p6K/Bi4GHgx6fcnbFI8mLgTaxsoE3TtQwC+weAs4B3Trc7x3cqB8CSXxsx3CbJGuBFwJePc+xi9S8Da9s5FrvWOE1ybJM08XEluQ6YAa4ZywgWN5XXrKr+m8Ejhh8beQSLm+TYXgW8DJhPsh94QZL5cQ3kGCb6ulXV4+2p5NeBDzB4XHTqmvYkxGILgw+pPcZg8uXIRMsrjmpzNc+evLmzrb+CZ0/ePMZg4mbRcwJ/zLMngd+2WsY2dM79rOwk8KRfs58B/h54/mr6fWQwqf2ydmyA9wHvWw1jO8a1V3oSeNK/k+cOvW6/BVy/0r+bI/33mXYHlnjxLgP+icGM+7ta7d3AG9r68xj84Z5nMAn40qFj39WOewS49HjnbPWXtnPMt3OesYrG9gsMnlMeBv4FeP8qGdfhVvtUW35tNbxmDO7M/w74DPAgcCtD7wp6Lo/tGNdd0QCYwu/kR4Zetz8CXrjS4xtl8ZPAktSpU3kOQJK0ggwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI69b/jcnaG9EGHPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9674899644375732\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "weight = np.load(\"weight.npy\")\n",
    "fre = np.load(\"frequency.npy\")\n",
    "plt.hist(weight)\n",
    "plt.show()\n",
    "plt.hist(fre)\n",
    "plt.show()\n",
    "\n",
    "print np.sum(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-1., -2., -7.]), -3492.2450000000003, array([-1., -2., -7.]), array([1, 0], dtype=int32), array([0., 0., 0., 0.]), array([], dtype=int32))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1., -2., -7.])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadratic_solver(3,aaa.T,-ccc,0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_solver(n, M, bbb , regularizer):\n",
    "    qp_G = np.matmul(M, M.T)\n",
    "    qp_G += regularizer * np.eye(n)\n",
    "\n",
    "    qp_a = np.matmul(M, bbb)###np.zeros(n, dtype = np.float64)\n",
    "    \n",
    "    qp_C = np.zeros((n,n+1), dtype = np.float64)\n",
    "    for i in range(n):\n",
    "        qp_C[i,0] = 0.0\n",
    "        qp_C[i,i+1] = 0.0\n",
    "    qp_b = np.zeros(n+1, dtype = np.float64)\n",
    "    qp_b[0] = 0.0\n",
    "    meq = 0.0\n",
    "\n",
    "    res = quadprog.solve_qp(qp_G, qp_a, qp_C, qp_b, meq)\n",
    "    print res\n",
    "    w = res[0]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = np.load(\"weight.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.180e+02, 1.066e+03, 4.340e+02, 1.590e+02, 7.500e+01, 2.700e+01,\n",
       "        1.100e+01, 7.000e+00, 2.000e+00, 1.000e+00]),\n",
       " array([0.        , 0.09314198, 0.18628396, 0.27942594, 0.37256792,\n",
       "        0.4657099 , 0.55885188, 0.65199386, 0.74513584, 0.83827782,\n",
       "        0.9314198 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
